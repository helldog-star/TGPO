#!/bin/bash

# Condaç¯å¢ƒé…ç½®
CONDA_SH_PATH="/mnt/zhaorunsong/anaconda3/etc/profile.d/conda.sh"  # Condaåˆå§‹åŒ–è„šæœ¬è·¯å¾„
CONDA_ENV_NAME="tgpo"  # Condaç¯å¢ƒåç§°
BASE_DIR="/tmp/hx/models"

source $CONDA_SH_PATH
conda activate $CONDA_ENV_NAME

MODEL_PATH="$BASE_DIR/Qwen3-30B-A3B-Thinking-2507-aligned"
LOG_FILE="./prepare_train_vllm_server.log"

# ---------- ä¼ å…¥ Python çš„é…ç½®ï¼ˆå¯æŒ‰éœ€ä¿®æ”¹ï¼‰ ----------
SCRIPT_DIR="$(cd "$(dirname "$0")" && pwd)"
OUTPUT_DIR="${OUTPUT_DIR:-$SCRIPT_DIR}"
DATASET_PATH="${DATASET_PATH:-$BASE_DIR/datasets/Openr1-Math-46k-8192}"
OUTPUT_PARQUET_PATH_ORI="$OUTPUT_DIR/openr1.parquet"
OUTPUT_PARQUET_PATH="$OUTPUT_DIR/openr1.tgpo.parquet"
TEMP_CACHE_JSON_PATH="$OUTPUT_DIR/openr1_tgpo_cache.json"
VLLM_BASE_URL="${VLLM_BASE_URL:-http://localhost:8000/v1}"
MAX_WORKERS="${MAX_WORKERS:-32}"
BATCH_SIZE="${BATCH_SIZE:-16}"

echo "ğŸš€ æ•°æ®é¢„å¤„ç†..."
python prepare_train.py --dataset $DATASET_PATH --output $OUTPUT_PARQUET_PATH_ORI

echo "ğŸš€ æ­£åœ¨å¯åŠ¨ vLLM æœåŠ¡..."

# 2. åå°å¯åŠ¨ vLLM (æ³¨æ„æœ«å°¾çš„ & å’Œæ—¥å¿—é‡å®šå‘)
# > $LOG_FILE 2>&1 æŠŠæ—¥å¿—å†™åˆ°æ–‡ä»¶ï¼Œé¿å…å’Œ Python è„šæœ¬è¾“å‡ºæ··åœ¨ä¸€èµ·
vllm serve $MODEL_PATH \
    --max-model-len 16384 \
    --enable-reasoning \
    --reasoning-parser deepseek_r1 \
    --tensor-parallel-size 8 \
    --trust-remote-code \
    > $LOG_FILE 2>&1 &

# è·å– vLLM è¿›ç¨‹çš„ PIDï¼Œç”¨äºç¨åå…³é—­
SERVER_PID=$!
echo "vLLM PID: $SERVER_PID"

# 3. è®¾ç½®æ¸…ç†é™·é˜±ï¼šæ— è®ºè„šæœ¬æ˜¯æ­£å¸¸ç»“æŸè¿˜æ˜¯è¢« Ctrl+C ä¸­æ–­ï¼Œéƒ½ä¼šæ‰§è¡Œ kill
trap "echo 'ğŸ›‘ å…³é—­ vLLM æœåŠ¡...'; kill $SERVER_PID" EXIT

# 4. å¾ªç¯æ£€æŸ¥ vLLM æ˜¯å¦å¯åŠ¨å®Œæˆ
echo "â³ ç­‰å¾…æ¨¡å‹åŠ è½½ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)..."
echo "ä½ å¯ä»¥é€šè¿‡ 'tail -f $LOG_FILE' æŸ¥çœ‹åŠ è½½è¿›åº¦"

while true; do
    # å°è¯•è®¿é—® vLLM çš„å¥åº·æ£€æŸ¥æ¥å£
    if curl -s http://localhost:8000/health > /dev/null; then
        echo "âœ… vLLM æœåŠ¡å·²å°±ç»ªï¼"
        break
    fi
    sleep 10
done

# 5. è¿è¡Œ Python æ•°æ®å¤„ç†è„šæœ¬ï¼ˆvLLM é‡‡æ ·ï¼‰
echo "ğŸ å¼€å§‹è¿è¡Œ Python å¤„ç†è„šæœ¬ï¼ˆvLLM é‡‡æ ·ï¼‰..."
python "$SCRIPT_DIR/my_prepare_train.py" \
    --dataset-path "$OUTPUT_PARQUET_PATH_ORI" \
    --model-local-path "$MODEL_PATH" \
    --output-parquet-path "$OUTPUT_PARQUET_PATH" \
    --temp-cache-json-path "$TEMP_CACHE_JSON_PATH" \
    --vllm-base-url "$VLLM_BASE_URL" \
    --max-workers "$MAX_WORKERS" \
    --batch-size "$BATCH_SIZE"

# 6. éªŒè¯é‡‡æ ·ç»“æœï¼ˆmath_verifyï¼Œè¾“å‡º _correct / _wrongï¼‰
echo "ğŸ” éªŒè¯é‡‡æ ·ç»“æœ..."
python "$SCRIPT_DIR/my_verify.py" --input "$OUTPUT_PARQUET_PATH"

# 7. å»æ‰ target å‰çš„ <think>\nï¼Œè¾“å‡º _correct_nothink.parquet
CORRECT_PARQUET="${OUTPUT_PARQUET_PATH%.parquet}_correct.parquet"
NOTHINK_PARQUET="${OUTPUT_PARQUET_PATH%.parquet}_correct_nothink.parquet"
if [[ -f "$CORRECT_PARQUET" ]]; then
    echo "ğŸ“ å»æ‰ target å‰çš„ <think>\\n ..."
    python "$SCRIPT_DIR/my_post_process.py" --input "$CORRECT_PARQUET" --output "$NOTHINK_PARQUET"
    echo "ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼æœ€ç»ˆè®­ç»ƒæ•°æ®: $NOTHINK_PARQUET"
else
    echo "âš ï¸ æœªæ‰¾åˆ°æ­£ç¡®æ ·æœ¬æ–‡ä»¶ $CORRECT_PARQUETï¼Œè·³è¿‡ post_processã€‚"
    echo "ğŸ‰ ä»»åŠ¡å®Œæˆã€‚"
fi

# è„šæœ¬é€€å‡ºæ—¶ä¼šè‡ªåŠ¨è§¦å‘ trap é‡Œçš„ kill å‘½ä»¤