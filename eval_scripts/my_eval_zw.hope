[base]
type = ml-easy-job

[resource]
usergroup = hadoop-aipnlp
#queue = root.zw05_training_cluster.hadoop-aipnlp.llm_second
queue = root.zw05_training_cluster.hadoop-aipnlp.llm_debug

[roles]
workers = 1
worker.memory = 800000
worker.vcore = 80
worker.gcores80g = 4
worker.ports = 1
worker.script = sh my_eval_zw.sh

[am]
afo.app.am.resource.mb = 4096

[tensorboard]
with.tensor.board = false
board.vcore = 64
board.memory = 40960
board.log_dir = /path/to/log_dir

[docker]
afo.docker.image.name = registry-offlinebiz.sankuai.com/custom_prod/com.sankuai.phxmlp.mtjupyter.singleuser/aipnlp_training_cuda12.6_py310_glic2.32_torch2.7.1_fla2.8.3_vllm0.10.0_sglang_0.4.10_stable_1.0.0_c95a1472

[data]
afo.data.prefetch = false

[failover]
afo.app.support.engine.failover = true
afo.role.worker.task.attempt.max.retry = 1

[others]
afo.data.shm.buffer.size = 300240
afo.role.worker.env.YARN_CONTAINER_RUNTIME_DOCKER_SHM_SIZE_BYTES = 343597383680
afo.app.env.YARN_CONTAINER_RUNTIME_DOCKER_SHM_SIZE_BYTES = 343597383680
afo.app.env.YARN_CONTAINER_RUNTIME_DOCKER_ULIMITS = memlock=-1
afo.docker.rw.volume.paths = /cfs/hadoop-aipnlp:/cfs/hadoop-aipnlp,/cfs/hadoop-mlp-ckpt:/cfs/hadoop-mlp-ckpt,/cfs_standard/hadoop-aipnlp:/cfs2/hadoop-aipnlp,/mnt/dolphinfs/hdd_pool/docker/user/hadoop-aipnlp:/mnt/dolphinfs/hdd_pool/docker/user/hadoop-aipnlp
afo.network.mode = RDMA
with_requirements = false
afo.afo-base.image.version = llm_sup
afo.dolphinfs.otherusers = hadoop-aipnlp,hadoop-mlp-ckpt
afo.use.hdfs.fuse = true
afo.use.hdfs.fuse.subpath = user:/mnt/hdfs/user,zw04mlnn01:/mnt/hdfs/zw04mlnn01
afo.use.hdfs.fuse.readonly = false
client.git.repo.dirty = true
